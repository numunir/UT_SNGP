{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 17:01:13.626057: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-23 17:01:13.626112: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-23 17:01:13.626131: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-23 17:01:13.630947: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import official.nlp.modeling.layers as nlp_layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n"
     ]
    }
   ],
   "source": [
    "# use respective file name for each data_set \n",
    "# For Example (modified_data_SNR5,modified_data_SNR7,modified_data_SNR10)\n",
    "data_file = open(\"Database_old_n_SNR20.csv\",'r')\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()\n",
    "[no_of_samples,] = np.shape(data_list)\n",
    "print (no_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = []\n",
    "lab = []\n",
    "for i in range (no_of_samples):\n",
    "    all_values = data_list[i].split(',')\n",
    "    all_values1 = np.asfarray(all_values[1:])\n",
    "    array_data = np.array(all_values1, dtype = 'f')\n",
    "    array_data = np.abs(array_data)\n",
    "    array_data = array_data/max(array_data)\n",
    "    y = all_values[0]\n",
    "    vec.append(array_data)\n",
    "    lab.append(y)\n",
    "    pass\n",
    "vec = np.reshape(vec,(no_of_samples,2048)) \n",
    "lab = np.reshape(lab,(no_of_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.array(lab.astype(int)) #Labels are stored in y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_data = vec\n",
    "array_data = np.array(array_data, dtype = 'f') #Signal vectors are stored in array_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Random Shuffling of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 3597 3598 3599]\n",
      "[1303 1009  764 ... 1653 2607 2732]\n"
     ]
    }
   ],
   "source": [
    "ran = np.arange(no_of_samples)\n",
    "print (ran)\n",
    "np.random.seed(seed = 0)\n",
    "np.random.shuffle(ran)\n",
    "print (ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_data = array_data[ran,:]\n",
    "y_data = y_data[ran]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 2048)\n",
      "(3600,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(array_data))\n",
    "print (np.shape(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting of Data into Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = []\n",
    "X_Test = []\n",
    "Y_Train = []\n",
    "Y_Test = []\n",
    "for train_index, test_index in skf.split(array_data,y_data):\n",
    "    X_train, X_test = array_data[train_index], array_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "    X_Train.append(X_train)\n",
    "    X_Test.append(X_test)\n",
    "    Y_Train.append(y_train)\n",
    "    Y_Test.append(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNGP CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UT_SNGP(tf.keras.Model):\n",
    "    def __init__(self, num_classes, spec_norm_bound=0.9, conv_actfn = 'elu', actfn = 'relu', **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.actfn = actfn\n",
    "        self.conv_actfn = conv_actfn\n",
    "        self.spec_norm_bound = spec_norm_bound\n",
    "        self.num_classes = num_classes\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        # hidden layers.\n",
    "        \n",
    "        self.conv_layers1 = nlp_layers.SpectralNormalization(self.make_conv_layer(32, (1,25), (1,8)), norm_multiplier=self.spec_norm_bound)\n",
    "\n",
    "        self.conv_layers2 = nlp_layers.SpectralNormalization(self.make_conv_layer(64, (1,3), (1,2)), norm_multiplier=self.spec_norm_bound)\n",
    "\n",
    "        self.pool_layers1 = self.make_pool_layer((1,2),(1,2))\n",
    "\n",
    "        self.conv_layers3 = nlp_layers.SpectralNormalization(self.make_conv_layer(64, (1,3), (1,2)), norm_multiplier=self.spec_norm_bound)\n",
    "\n",
    "        self.pool_layers2 = self.make_pool_layer((1,2),(1,2))\n",
    "\n",
    "        self.conv_layers4 = nlp_layers.SpectralNormalization(self.make_conv_layer(64, (1,3), (1,2)), norm_multiplier=self.spec_norm_bound)\n",
    "\n",
    "        self.pool_layers3 = self.make_pool_layer((1,2),(1,2))\n",
    "\n",
    "        self.flatten_layer = self.make_flat_layer()\n",
    "        \n",
    "        self.dense_layers1 = nlp_layers.SpectralNormalization(self.make_dense_layer(256), norm_multiplier=self.spec_norm_bound)\n",
    "        self.dense_layers2 = nlp_layers.SpectralNormalization(self.make_dense_layer(256), norm_multiplier=self.spec_norm_bound)\n",
    "\n",
    "        self.classifier = self.make_output_layer(num_classes)\n",
    "\n",
    "    def call(self, inputs, training=True, return_covmat=False):\n",
    "        \n",
    "        conv1 = self.conv_layers1(inputs)\n",
    "        conv2 = self.conv_layers2(conv1)\n",
    "        pool1 = self.pool_layers1(conv2)\n",
    "        conv3 = self.conv_layers3(pool1)\n",
    "        pool2 = self.pool_layers2(conv3)\n",
    "        conv4 = self.conv_layers4(pool2)\n",
    "        pool3 = self.pool_layers3(conv4)\n",
    "        flat = self.flatten_layer(pool3)\n",
    "        dense1 = self.dense_layers1(flat)\n",
    "        dense2 = self.dense_layers2(dense1)\n",
    "\n",
    "        logits, covmat = self.classifier(dense2)\n",
    "\n",
    "        if not training and return_covmat:\n",
    "          return logits, covmat\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def make_dense_layer(self, hidden_units):\n",
    "        \"\"\"Use the Dense layer as the hidden layer.\"\"\"\n",
    "        return tf.keras.layers.Dense(hidden_units, activation=self.actfn)\n",
    "\n",
    "    def make_conv_layer(self, conv_filters, conv_kernel, conv_stride):\n",
    "        \"\"\"Use the Conv layer as the hidden layer.\"\"\"\n",
    "        return tf.keras.layers.Conv2D(filters = conv_filters, kernel_size= conv_kernel, strides = conv_stride, activation= self.conv_actfn,\n",
    "                                      padding=\"SAME\")\n",
    "\n",
    "    def make_pool_layer(self, cpool_size, pool_stride):\n",
    "        \"\"\"Use the pool layer as the hidden layer.\"\"\"\n",
    "        return tf.keras.layers.MaxPooling2D(pool_size= cpool_size, strides = pool_stride, padding = \"VALID\")\n",
    "\n",
    "    def make_flat_layer(self):\n",
    "        \"\"\"Use the flatten layer as the hidden layer.\"\"\"\n",
    "        return tf.keras.layers.Flatten()\n",
    "\n",
    "    def make_output_layer(self, num_classes):\n",
    "        \"\"\"the output layer.\"\"\"\n",
    "        return nlp_layers.RandomFeatureGaussianProcess(num_classes,gp_cov_momentum=-1,\n",
    "                                                       gp_kernel_scale_trainable=True, \n",
    "                                                       num_inducing=64, \n",
    "                                                       gp_kernel_scale=0.0001, **self.kwargs)\n",
    "\n",
    "class ResetCovarianceCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"Resets covariance matrix at the beginning of the epoch.\"\"\"\n",
    "        if epoch > 0:\n",
    "            self.model.classifier.reset_covariance_matrix()\n",
    "\n",
    "class UT_SNGPWithCovReset(UT_SNGP):\n",
    "    def fit(self, *args, **kwargs):\n",
    "        \"\"\"Adds ResetCovarianceCallback to model callbacks.\"\"\"\n",
    "        kwargs[\"callbacks\"] = list(kwargs.get(\"callbacks\", []))\n",
    "        kwargs[\"callbacks\"].append(ResetCovarianceCallback())\n",
    "        return super().fit(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 17:01:27.900912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:27.907966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:27.908001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:27.909681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:27.909726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:27.909746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:28.019012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:28.019064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:28.019073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-23 17:01:28.019109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 17:01:28.019127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5582 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-06-23 17:01:28.264960: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "UT_model = UT_SNGP(num_classes = 5, spec_norm_bound=0.9, conv_actfn = 'elu', actfn = 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "UT_model.build((None,1,2048,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ut_sngp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " spectral_normalization (Sp  multiple                  889       \n",
      " ectralNormalization)                                            \n",
      "                                                                 \n",
      " spectral_normalization_1 (  multiple                  6368      \n",
      " SpectralNormalization)                                          \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " spectral_normalization_2 (  multiple                  12608     \n",
      " SpectralNormalization)                                          \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " spectral_normalization_3 (  multiple                  12608     \n",
      " SpectralNormalization)                                          \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " spectral_normalization_4 (  multiple                  66304     \n",
      " SpectralNormalization)                                          \n",
      "                                                                 \n",
      " spectral_normalization_5 (  multiple                  66304     \n",
      " SpectralNormalization)                                          \n",
      "                                                                 \n",
      " random_feature_gaussian_pr  multiple                  20869     \n",
      " ocess (RandomFeatureGaussi                                      \n",
      " anProcess)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 185950 (726.37 KB)\n",
      "Trainable params: 163648 (639.25 KB)\n",
      "Non-trainable params: 22302 (87.12 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "UT_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "UT_model = UT_SNGPWithCovReset(num_classes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = dict(loss=loss, metrics=metrics, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "UT_model.compile(**train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "x_train = np.reshape(X_Train[i],[-1,1,2048,1])\n",
    "x_test = np.reshape(X_Test[i],[-1,1,2048,1])\n",
    "y_train = Y_Train[i]\n",
    "y_test = Y_Test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_config = dict(batch_size=600, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 17:01:36.845971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-06-23 17:01:36.928425: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "H = UT_model.fit(x_train, y_train, validation_data=(x_test, y_test), verbose = False,**fit_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = pd.DataFrame(H.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accu=[]\n",
    "test_accu.append(max(accu['val_sparse_categorical_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9944444298744202]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Saving and Uncertainty Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior_mean_probability(logits, covmat, lambda_param=np.pi / 8.):\n",
    "    # Computes uncertainty-adjusted logits using the built-in method.\n",
    "    logits_adjusted = nlp_layers.gaussian_process.mean_field_logits(\n",
    "    logits, covmat, mean_field_factor=lambda_param)\n",
    "  \n",
    "    #return tf.nn.softmax(logits_adjusted, axis=-1)[:, 0]\n",
    "    return tf.nn.softmax(logits_adjusted, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 17:03:40.154025: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x1fe9f960\n"
     ]
    }
   ],
   "source": [
    "UT_logits, UT_covmat = UT_model(x_test, training = False, return_covmat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "UT_probs = compute_posterior_mean_probability(UT_logits, UT_covmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(360, 5), dtype=float32, numpy=\n",
       "array([[0.98463535, 0.0051801 , 0.00196744, 0.00418706, 0.00403009],\n",
       "       [0.97684485, 0.00603159, 0.00266852, 0.00427389, 0.01018109],\n",
       "       [0.00339106, 0.9921531 , 0.0014965 , 0.00132811, 0.00163125],\n",
       "       ...,\n",
       "       [0.00528874, 0.9896107 , 0.00165717, 0.00154405, 0.00189935],\n",
       "       [0.00500088, 0.98964816, 0.00188019, 0.00168828, 0.00178252],\n",
       "       [0.00503237, 0.9874686 , 0.00252173, 0.00262658, 0.00235076]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UT_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = UT_probs * (1. - UT_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncertain = pd.DataFrame(uncertainty,columns = ['C','LF','LP','P','S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncertain.to_csv(r'SNGP_UT_Uncertainty_SNR20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = pd.DataFrame(y_test,columns = ['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab.to_csv(r'SNGP_UT_Labels_SNR20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob = pd.DataFrame(UT_probs,columns = ['C','LF','LP','P','S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob.to_csv(r'SNGP_UT_Probs_SNR20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "0.023152513\n",
      "LF\n",
      "0.03952577\n",
      "LP\n",
      "0.03961556\n",
      "P\n",
      "0.022898976\n",
      "S\n",
      "0.03452117\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    na = i\n",
    "    a = df_lab.labels[df_lab.labels==na].index.tolist()\n",
    "    col = ['C','LF','LP','P','S']\n",
    "    col_l = col[na]\n",
    "    b = df_uncertain[col_l]\n",
    "    c = b[a]\n",
    "    avg = np.average(c)\n",
    "    print(col[na])\n",
    "    print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
